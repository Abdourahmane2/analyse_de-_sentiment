{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 tweets collectés et sauvegardés dans 'tweets_data.csv'\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from twikit import Client, TooManyRequests\n",
    "from configparser import ConfigParser\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import re \n",
    "import emoji\n",
    "\n",
    "# Constantes\n",
    "MINIMUMS = 100\n",
    "REQUETE = 'ballon d\\'or lang:fr '  \n",
    "# Lire les informations de connexion depuis le fichier config.ini\n",
    "config = ConfigParser()\n",
    "config.read('config.ini')\n",
    "username = config['X']['username']\n",
    "email = config['X']['email']\n",
    "password = config['X']['password']\n",
    "\n",
    "client = Client(language='fr-FR')  # Configurer pour obtenir des résultats en français\n",
    "\n",
    "# Fonction principale async\n",
    "async def main():\n",
    "    # Authentification\n",
    "    await client.login(auth_info_1=username, auth_info_2=email, password=password)\n",
    "    \n",
    "    # Sauvegarder les cookies après l'authentification\n",
    "    client.save_cookies('cookies.json')\n",
    "    client.load_cookies('cookies.json')  # Charger les cookies pour les sessions futures\n",
    "\n",
    "    # Initialisation de la liste pour les tweets et compteur\n",
    "    donne = []\n",
    "    tweet_count = 0\n",
    "    debut = (datetime.now() - timedelta(days=60)).strftime('%Y-%m-%d') \n",
    "    fin = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Rechercher les tweets avec la requête spécifiée\n",
    "    tweets = await client.search_tweet(REQUETE + f\" since:{debut} until:{fin}\", product='Top')\n",
    "  \n",
    "    \n",
    "    # Boucle pour paginer les tweets\n",
    "    while tweet_count < MINIMUMS:\n",
    "            # Récupérer la page suivante de tweets\n",
    "            encore = await tweets.next()\n",
    "\n",
    "            for tweet in encore:\n",
    "                post_data = {\n",
    "                    'Texte': tweet.full_text,\n",
    "                    'Nombre_Likes': tweet.favorite_count,\n",
    "                    'Nombre_Retweets': tweet.retweet_count,\n",
    "                    'Followers_Utilisateur': tweet.user.followers_count,\n",
    "                    'Utilisateur': tweet.user.screen_name,\n",
    "                    'Date_Publication': tweet.created_at\n",
    "                }\n",
    "                donne.append(post_data)\n",
    "                tweet_count += 1\n",
    "\n",
    "            \n",
    "                if tweet_count >= MINIMUMS:\n",
    "                    break\n",
    "           \n",
    "        \n",
    "\n",
    "    if donne:\n",
    "        df = pd.DataFrame(donne)\n",
    "        df.to_csv('tweets_data.csv', index=False)\n",
    "        print(f\"{len(df)} tweets collectés et sauvegardés dans 'tweets_data.csv'\")\n",
    "    else:\n",
    "        print(\"Aucune donnée collectée.\")\n",
    "\n",
    "# Exécuter la fonction async\n",
    "await main()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Cest toujours quand cest un noir qui doit gagn...\n",
       "1    Le ballon dor féminin cest comme quand on donn...\n",
       "2    Cest carrément gênant  tout façon cest vini no...\n",
       "3    Jour de    Golden Boy  Trophée Kopa  Top 10 ba...\n",
       "4    Rodri ma fait vibrer la saison passée donc je ...\n",
       "Name: Texte, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "donne = pd.read_csv('tweets_data.csv')\n",
    "donne.head()\n",
    "\n",
    "#appliquer des nettoyages\n",
    "def netoyer(text): \n",
    "    text = re.sub(r'http\\S+', '', text) # Supprimer les liens \n",
    "    text = re.sub(r'www\\S+', '', text) # Supprimer les liens www \n",
    "    text = re.sub(r'@\\w+', '', text) # Supprimer les mentions \n",
    "    text = re.sub(r'#\\w+', '', text) # Supprimer les hashtags \n",
    "    text = re.sub(r'\\n', ' ', text) # Supprimer les sauts de ligne \n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Supprimer les caractères de ponctuation \n",
    "    text = emoji.replace_emoji(text, '') # Supprimer les emojis return \n",
    "    text.strip() # Enlever les espaces inutiles\n",
    "    return text\n",
    "\n",
    "#appliquer le netooyage\n",
    "donne['Texte'] = donne['Texte'].apply(netoyer)\n",
    "donne['Texte'].head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFDistilBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Créer un pipeline d'analyse de sentiment en utilisant DistilBERT\n",
    "sentiment = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "# Analyser un texte\n",
    "def analyze_sentiment(text): \n",
    "    result = sentiment(text)[0] \n",
    "    return result['label'], result['score']\n",
    "donne[['Sentiment_Label', 'Sentiment_Score']] = donne['Texte'].apply(lambda x: pd.Series(analyze_sentiment(x)))\n",
    "donne[['Texte', 'Sentiment_Label', 'Sentiment_Score']].head()\n",
    "\n",
    "#enregistre dans le fichier csv\n",
    "donne.to_csv('tweets_data.csv', index=False)\n",
    "\n",
    "   \n",
    "#donne.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3789\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3790\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3791\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[81], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Distribution des Sentiments\u001b[39;00m\n\u001b[0;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m----> 8\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mdonne\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistribution des Sentiments\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType de Sentiment\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3891\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3895\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3792\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3793\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3794\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3795\u001b[0m     ):\n\u001b[0;32m   3796\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3797\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3799\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Charger les données des tweets depuis un fichier CSV (assurant que tu as une colonne 'Sentiment_Label')\n",
    "df = pd.read_csv('tweets_data.csv')\n",
    "\n",
    "# Visualisation de la Distribution des Sentiments\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=df, x='Sentiment_Label', palette='viridis')\n",
    "plt.title('Distribution des Sentiments')\n",
    "plt.xlabel('Type de Sentiment')\n",
    "plt.ylabel('Nombre de Tweets')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
